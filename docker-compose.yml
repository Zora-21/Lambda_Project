services:

  ###############################
  #  BATCH LAYER (HADOOP)
  ###############################
  
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: namenode
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
      - HDFS_CONF_dfs_datanode_use_datanode_hostname=true
      - HDFS_CONF_dfs_client_use_datanode_hostname=true 
    ports:
      - "9870:9870"
      - "9000:9000"
    networks:
      - lambda-net
    healthcheck: # Aggiunto healthcheck per stabilità
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: datanode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
      HDFS_CONF_dfs_replication: 1
      HDFS_CONF_dfs_datanode_use_datanode_hostname: "true" 
    depends_on:
      namenode:
        condition: service_healthy
    networks:
      - lambda-net
    healthcheck: # Aggiunto healthcheck per stabilità
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: resourcemanager
    ports:
      - "8088:8088"
    environment:
      - SERVICE_PRECONDITION=namenode:9870;datanode:9864
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
    networks:
      - lambda-net
    healthcheck: # Aggiunto healthcheck per stabilità
      test: ["CMD", "curl", "-f", "http://localhost:8088/ws/v1/cluster/info"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  nodemanager:
    build: 
      context: ./hadoop-nodemanager-custom
    platform: linux/amd64
    container_name: nodemanager
    volumes:
      - ./hadoop-job:/app
    environment:
      - SERVICE_PRECONDITION=resourcemanager:8088
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    depends_on:
      resourcemanager:
        condition: service_healthy
    networks:
      - lambda-net

  ###############################
  #  SPEED LAYER (CASSANDRA)
  ###############################
  
  cassandra-seed:
    image: cassandra:4.1
    platform: linux/amd64
    container_name: cassandra-seed
    restart: on-failure
    ports:
      - "9042:9042"
    volumes:
      - cassandra_data:/var/lib/cassandra
      # Questo file init.cql viene ignorato se usiamo lo script start.py
      # ma lo lasciamo per completezza se dovessimo rimuovere start.py
      - ./cassandra-config:/docker-entrypoint-initdb.d 
    environment:
      - CASSANDRA_CLUSTER_NAME=IoTCluster
      - CASSANDRA_SEEDS=cassandra-seed
      - MAX_HEAP_SIZE=512M 
      - HEAP_NEWSIZE=128M
    mem_limit: 2g
    networks:
      - lambda-net
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 90s

  cassandra-node1:
    image: cassandra:4.1
    platform: linux/amd64
    container_name: cassandra-node1
    restart: on-failure
    environment:
      - CASSANDRA_CLUSTER_NAME=IoTCluster
      - CASSANDRA_SEEDS=cassandra-seed
      - MAX_HEAP_SIZE=512M
      - HEAP_NEWSIZE=128M
    mem_limit: 2g
    depends_on:
      cassandra-seed:
        condition: service_healthy
    networks:
      - lambda-net

  ###############################
  #  SERVIZI APPLICATIVI
  ###############################

  init-services: # <-- (1) SERVIZIO NUOVO
    build:
      context: ./iot-producer # Riutilizza la stessa immagine del producer
    container_name: init-services
    command: ["python", "start.py"] # Esegue SOLO lo script di init
    depends_on:
      cassandra-seed:
        condition: service_healthy
      namenode:
        condition: service_healthy # Aggiungiamo anche HDFS
    networks:
      - lambda-net
    restart: on-failure # Riprova se l'init fallisce

  iot-producer:
    build:
      context: ./iot-producer
    container_name: iot-producer
    command: ["python", "producer.py"] # <-- (2) MODIFICATO: Esegue solo il producer
    depends_on:
      init-services: # <-- (3) MODIFICATO: Attende il completamento dell'init
        condition: service_completed_successfully
    networks:
      - lambda-net
    restart: on-failure

  dashboard:
    build:
      context: ./dashboard
    container_name: dashboard
    ports:
      - "5000:5000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./hadoop-job:/hadoop-job
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
    depends_on:
      init-services: # <-- (4) MODIFICATO: Attende il completamento dell'init
        condition: service_completed_successfully
      # Manteniamo le dipendenze originali
      cassandra-seed:
        condition: service_healthy
      resourcemanager:
        condition: service_healthy
    networks:
      - lambda-net

# Definizione della rete virtuale
networks:
  lambda-net:
    driver: bridge

# Definizione dei volumi per la persistenza
volumes:
  hadoop_namenode:
  hadoop_datanode:
  cassandra_data: